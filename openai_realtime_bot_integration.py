"""
–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç —Å OpenAI (Whisper + GPT + TTS)

–ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞:
1. Whisper - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏
2. GPT-4 - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
3. TTS - –æ–∑–≤—É—á–∫–∞ –æ—Ç–≤–µ—Ç–∞

–†–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –ª—é–±–æ–º OPENAI_API_KEY (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç –±–µ—Ç–∞-–¥–æ—Å—Ç—É–ø–∞)
"""

import logging
import subprocess
import tempfile
import os
from typing import Optional
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, ConversationHandler
from io import BytesIO
import asyncio
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

logger = logging.getLogger(__name__)

# –°–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
VOICE_CONVERSATION = 1

# OpenAI –∫–ª–∏–µ–Ω—Ç
openai_client: Optional[OpenAI] = None

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
VOICE_SYSTEM_PROMPT = """–í—ã ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-—ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤—É –¥–ª—è –†–æ—Å—Å–∏–∏.

–í–ê–ñ–ù–û - –í–´ –û–¢–í–ï–ß–ê–ï–¢–ï –ì–û–õ–û–°–û–ú:
- –û—Ç–≤–µ—á–∞–π—Ç–µ –ö–†–ê–¢–ö–û (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º—É–º)
- –ì–æ–≤–æ—Ä–∏—Ç–µ –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
- –ù–∞–∑—ã–≤–∞–π—Ç–µ –Ω–æ–º–µ—Ä–∞ –°–ü/–ì–û–°–¢ –∫–æ—Ä–æ—Ç–∫–æ
- –ü—Ä–∏ –æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≥–æ–≤–æ—Ä–∏—Ç–µ —á—ë—Ç–∫–æ: "–í–Ω–∏–º–∞–Ω–∏–µ! –û–ø–∞—Å–Ω–æ—Å—Ç—å!"

–í—ã –ø–æ–º–æ–≥–∞–µ—Ç–µ –ø—Ä–æ—Ä–∞–±–∞–º –Ω–∞ —Å—Ç—Ä–æ–π–∫–µ - —É –Ω–∏—Ö –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.
–Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π."""


def init_realtime_assistant() -> bool:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    global openai_client

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.warning("‚ö†Ô∏è OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False

    try:
        openai_client = OpenAI(api_key=api_key)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–ª–∏–µ–Ω—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç
        openai_client.models.list()
        logger.info("‚úÖ OpenAI Voice Assistant –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (Whisper + TTS)")
        return True
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI: {e}")
        return False


def is_openai_realtime_available() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏"""
    return openai_client is not None


def convert_ogg_to_mp3(ogg_bytes: bytes) -> Optional[bytes]:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç OGG –≤ MP3 –¥–ª—è Whisper"""
    try:
        with tempfile.NamedTemporaryFile(suffix='.ogg', delete=False) as ogg_file:
            ogg_file.write(ogg_bytes)
            ogg_path = ogg_file.name

        mp3_path = ogg_path.replace('.ogg', '.mp3')

        result = subprocess.run(
            ['ffmpeg', '-y', '-i', ogg_path, '-acodec', 'libmp3lame', '-q:a', '4', mp3_path],
            capture_output=True,
            timeout=30
        )

        if result.returncode == 0 and os.path.exists(mp3_path):
            with open(mp3_path, 'rb') as f:
                mp3_bytes = f.read()
            os.unlink(ogg_path)
            os.unlink(mp3_path)
            return mp3_bytes

        os.unlink(ogg_path)
        return None

    except FileNotFoundError:
        logger.warning("‚ö†Ô∏è ffmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        return None
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
        return None


async def transcribe_audio(audio_bytes: bytes) -> Optional[str]:
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ Whisper"""
    if not openai_client:
        return None

    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ MP3
        mp3_bytes = convert_ogg_to_mp3(audio_bytes)
        if not mp3_bytes:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ")
            return None

        # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as f:
            f.write(mp3_bytes)
            temp_path = f.name

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Whisper
        with open(temp_path, 'rb') as audio_file:
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ru"
            )

        os.unlink(temp_path)
        return transcript.text

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Whisper: {e}")
        return None


async def generate_response(user_message: str, context_messages: list = None) -> Optional[str]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ GPT"""
    if not openai_client:
        return None

    try:
        messages = [{"role": "system", "content": VOICE_SYSTEM_PROMPT}]

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        if context_messages:
            messages.extend(context_messages[-6:])  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3 –æ–±–º–µ–Ω–∞

        messages.append({"role": "user", "content": user_message})

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",  # –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –≥–æ–ª–æ—Å–∞
            messages=messages,
            max_tokens=150,  # –ö–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è –≥–æ–ª–æ—Å–∞
            temperature=0.7
        )

        return response.choices[0].message.content

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ GPT: {e}")
        return None


async def text_to_speech(text: str) -> Optional[bytes]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å —á–µ—Ä–µ–∑ OpenAI TTS"""
    if not openai_client:
        return None

    try:
        response = openai_client.audio.speech.create(
            model="tts-1",
            voice="onyx",  # –ú—É–∂—Å–∫–æ–π –≥–æ–ª–æ—Å, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞
            input=text,
            response_format="opus"
        )

        return response.content

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ TTS: {e}")
        return None


# ============================================================================
# –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò
# ============================================================================

async def start_realtime_chat_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ö–æ–º–∞–Ω–¥–∞ /realtime_chat - –ù–∞—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–π —Ä–∞–∑–≥–æ–≤–æ—Ä"""

    if not openai_client:
        await update.message.reply_text(
            "‚ùå –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n"
            "–¢—Ä–µ–±—É–µ—Ç—Å—è OPENAI_API_KEY."
        )
        return ConversationHandler.END

    user_id = update.effective_user.id

    # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context.user_data['voice_messages'] = []

    keyboard = [
        [InlineKeyboardButton("üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å", callback_data="stop_realtime_chat")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await update.message.reply_text(
        "üé§ **–ì–û–õ–û–°–û–í–û–ô –ê–°–°–ò–°–¢–ï–ù–¢**\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —è –æ—Ç–≤–µ—á—É –≥–æ–ª–æ—Å–æ–º!\n\n"
        "‚Ä¢ üé§ –ì–æ–≤–æ—Ä–∏—Ç–µ –∫—Ä–∞—Ç–∫–æ –∏ —á—ë—Ç–∫–æ\n"
        "‚Ä¢ üí¨ –ú–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º\n"
        "‚Ä¢ üîä –û—Ç–≤–µ—Ç –ø—Ä–∏–¥—ë—Ç –≥–æ–ª–æ—Å–æ–º\n\n"
        "_Whisper + GPT-4 + TTS_",
        parse_mode="Markdown",
        reply_markup=reply_markup
    )

    return VOICE_CONVERSATION


async def start_realtime_chat_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Entry point —á–µ—Ä–µ–∑ callback –∫–Ω–æ–ø–∫–∏ (–¥–ª—è ConversationHandler)"""
    query = update.callback_query
    await query.answer("üé§ –ó–∞–ø—É—Å–∫–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç...")

    if not openai_client:
        await query.edit_message_text(
            "‚ùå –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.\n"
            "–¢—Ä–µ–±—É–µ—Ç—Å—è OPENAI_API_KEY."
        )
        return ConversationHandler.END

    # –û—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context.user_data['voice_messages'] = []

    keyboard = [
        [InlineKeyboardButton("üõë –ó–∞–≤–µ—Ä—à–∏—Ç—å", callback_data="stop_realtime_chat")]
    ]
    reply_markup = InlineKeyboardMarkup(keyboard)

    await context.bot.send_message(
        chat_id=query.message.chat_id,
        text="üé§ **–ì–û–õ–û–°–û–í–û–ô –ê–°–°–ò–°–¢–ï–ù–¢**\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ ‚Äî —è –æ—Ç–≤–µ—á—É –≥–æ–ª–æ—Å–æ–º!\n\n"
        "‚Ä¢ üé§ –ì–æ–≤–æ—Ä–∏—Ç–µ –∫—Ä–∞—Ç–∫–æ –∏ —á—ë—Ç–∫–æ\n"
        "‚Ä¢ üí¨ –ú–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º\n"
        "‚Ä¢ üîä –û—Ç–≤–µ—Ç –ø—Ä–∏–¥—ë—Ç –≥–æ–ª–æ—Å–æ–º\n\n"
        "_Whisper + GPT-4 + TTS_",
        parse_mode="Markdown",
        reply_markup=reply_markup
    )

    return VOICE_CONVERSATION


async def handle_realtime_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"""

    if not openai_client:
        await update.message.reply_text("‚ùå –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return VOICE_CONVERSATION

    try:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        processing_msg = await update.message.reply_text("üéß –°–ª—É—à–∞—é...")

        # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ
        voice = update.message.voice
        voice_file = await voice.get_file()
        ogg_bytes = await voice_file.download_as_bytearray()

        # 1. –†–∞—Å–ø–æ–∑–Ω–∞—ë–º —Ä–µ—á—å
        await processing_msg.edit_text("üé§ –†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å...")
        user_text = await transcribe_audio(bytes(ogg_bytes))

        if not user_text:
            await processing_msg.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
            return VOICE_CONVERSATION

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Å–∫–∞–∑–∞–ª –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        await processing_msg.edit_text(f"üí¨ –í—ã: _{user_text}_\n\n‚è≥ –î—É–º–∞—é...", parse_mode="Markdown")

        # 2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        voice_messages = context.user_data.get('voice_messages', [])
        bot_response = await generate_response(user_text, voice_messages)

        if not bot_response:
            await processing_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.")
            return VOICE_CONVERSATION

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        voice_messages.append({"role": "user", "content": user_text})
        voice_messages.append({"role": "assistant", "content": bot_response})
        context.user_data['voice_messages'] = voice_messages

        # 3. –û–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
        await processing_msg.edit_text(f"üí¨ –í—ã: _{user_text}_\n\nüîä –û–∑–≤—É—á–∏–≤–∞—é...", parse_mode="Markdown")
        audio_response = await text_to_speech(bot_response)

        # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Å—Ç–∞—Ç—É—Å–µ
        await processing_msg.delete()

        if audio_response:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç
            audio_file = BytesIO(audio_response)
            audio_file.name = "response.ogg"

            await update.message.reply_voice(
                voice=audio_file,
                caption=f"üìù _{bot_response}_",
                parse_mode="Markdown"
            )
        else:
            # –ï—Å–ª–∏ TTS –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–º
            await update.message.reply_text(
                f"üí¨ –í—ã: _{user_text}_\n\n"
                f"ü§ñ **–û—Ç–≤–µ—Ç:**\n{bot_response}",
                parse_mode="Markdown"
            )

        return VOICE_CONVERSATION

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)[:100]}")
        return VOICE_CONVERSATION


async def handle_realtime_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è - —Ç–æ–∂–µ –æ—Ç–≤–µ—á–∞–µ–º –≥–æ–ª–æ—Å–æ–º"""

    if not openai_client:
        await update.message.reply_text("‚ùå –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return VOICE_CONVERSATION

    try:
        user_text = update.message.text

        processing_msg = await update.message.reply_text("‚è≥ –î—É–º–∞—é...")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        voice_messages = context.user_data.get('voice_messages', [])
        bot_response = await generate_response(user_text, voice_messages)

        if not bot_response:
            await processing_msg.edit_text("‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.")
            return VOICE_CONVERSATION

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        voice_messages.append({"role": "user", "content": user_text})
        voice_messages.append({"role": "assistant", "content": bot_response})
        context.user_data['voice_messages'] = voice_messages

        # –û–∑–≤—É—á–∏–≤–∞–µ–º
        await processing_msg.edit_text("üîä –û–∑–≤—É—á–∏–≤–∞—é...")
        audio_response = await text_to_speech(bot_response)

        await processing_msg.delete()

        if audio_response:
            audio_file = BytesIO(audio_response)
            audio_file.name = "response.ogg"

            await update.message.reply_voice(
                voice=audio_file,
                caption=f"üìù _{bot_response}_",
                parse_mode="Markdown"
            )
        else:
            await update.message.reply_text(f"ü§ñ {bot_response}")

        return VOICE_CONVERSATION

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        await update.message.reply_text(f"‚ùå –û—à–∏–±–∫–∞: {str(e)[:100]}")
        return VOICE_CONVERSATION


async def stop_realtime_chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —á–∞—Ç–∞"""

    voice_messages = context.user_data.get('voice_messages', [])
    exchanges = len(voice_messages) // 2

    context.user_data['voice_messages'] = []

    await update.effective_message.reply_text(
        f"üõë **–ì–æ–ª–æ—Å–æ–≤–æ–π —á–∞—Ç –∑–∞–≤–µ—Ä—à—ë–Ω**\n\n"
        f"üìä –û–±–º–µ–Ω–æ–≤: {exchanges}\n\n"
        f"–î–ª—è –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞: /realtime_chat",
        parse_mode="Markdown"
    )

    return ConversationHandler.END


async def cancel_realtime_chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û—Ç–º–µ–Ω–∞"""
    return await stop_realtime_chat(update, context)


async def realtime_chat_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Callback –∫–Ω–æ–ø–æ–∫"""
    query = update.callback_query
    await query.answer()

    if query.data == "stop_realtime_chat":
        return await stop_realtime_chat(update, context)

    return VOICE_CONVERSATION


# ============================================================================
# –°–ü–†–ê–í–ö–ê
# ============================================================================

async def realtime_help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–°–ø—Ä–∞–≤–∫–∞ –ø–æ –≥–æ–ª–æ—Å–æ–≤–æ–º—É —á–∞—Ç—É"""
    await update.message.reply_text(
        "üé§ **–ì–û–õ–û–°–û–í–û–ô –ê–°–°–ò–°–¢–ï–ù–¢**\n\n"
        "**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç:**\n"
        "1Ô∏è‚É£ –í—ã –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
        "2Ô∏è‚É£ Whisper —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ä–µ—á—å\n"
        "3Ô∏è‚É£ GPT-4 –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç\n"
        "4Ô∏è‚É£ TTS –æ–∑–≤—É—á–∏–≤–∞–µ—Ç –æ—Ç–≤–µ—Ç\n\n"
        "**–ö–æ–º–∞–Ω–¥—ã:**\n"
        "‚Ä¢ `/realtime_chat` - –ù–∞—á–∞—Ç—å\n"
        "‚Ä¢ –ö–Ω–æ–ø–∫–∞ \"–ó–∞–≤–µ—Ä—à–∏—Ç—å\" - –ó–∞–∫–æ–Ω—á–∏—Ç—å\n\n"
        "**–°–æ–≤–µ—Ç—ã:**\n"
        "‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç–µ —á—ë—Ç–∫–æ –∏ –∫—Ä–∞—Ç–∫–æ\n"
        "‚Ä¢ –ú–æ–∂–Ω–æ –ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º ‚Äî –æ—Ç–≤–µ—Ç –≥–æ–ª–æ—Å–æ–º\n"
        "‚Ä¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ —Ä–∞–º–∫–∞—Ö —Å–µ—Å—Å–∏–∏",
        parse_mode="Markdown"
    )


# ============================================================================
# –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø
# ============================================================================

def register_realtime_assistant_handlers(application):
    """–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"""
    from telegram.ext import (
        CommandHandler,
        MessageHandler,
        CallbackQueryHandler,
        ConversationHandler,
        filters
    )

    conv_handler = ConversationHandler(
        entry_points=[
            CommandHandler("realtime_chat", start_realtime_chat_command),
            CallbackQueryHandler(start_realtime_chat_callback, pattern="^realtime_chat_start$")
        ],
        states={
            VOICE_CONVERSATION: [
                MessageHandler(filters.VOICE, handle_realtime_voice),
                MessageHandler(filters.TEXT & ~filters.COMMAND, handle_realtime_text),
                CallbackQueryHandler(realtime_chat_callback),
            ]
        },
        fallbacks=[
            CommandHandler("cancel", cancel_realtime_chat),
            CommandHandler("stop", stop_realtime_chat),
        ],
        name="voice_chat_conversation",
        persistent=False
    )

    application.add_handler(conv_handler)
    application.add_handler(CommandHandler("realtime_help", realtime_help_command))

    logger.info("‚úÖ –ì–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (Whisper+TTS) –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω")
