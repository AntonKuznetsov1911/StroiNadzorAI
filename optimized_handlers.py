"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö AI –º–æ–¥–µ–ª–µ–π
–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ bot.py –¥–ª—è —É–º–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–¥–∞—á
"""

import logging
import asyncio
from typing import Dict, Optional
import os

logger = logging.getLogger(__name__)


# ============================================================================
# –û–ë–†–ê–ë–û–¢–ß–ò–ö GROK (–ø—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã, web search)
# ============================================================================

async def handle_with_grok(
    question: str,
    user_id: int,
    conversation_history: list,
    system_prompt: str,
    needs_web_search: bool = False
) -> str:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ xAI Grok

    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        conversation_history: –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        needs_web_search: –ù—É–∂–µ–Ω –ª–∏ –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ

    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç Grok
    """
    logger.info(f"üü¢ –ò—Å–ø–æ–ª—å–∑—É–µ–º Grok {'—Å web search' if needs_web_search else '–±–µ–∑ web search'}")

    try:
        from xai_client import XAIClient

        xai_client = XAIClient(api_key=os.getenv("XAI_API_KEY"))

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = [{"role": "system", "content": system_prompt}]

        for msg in conversation_history:
            if msg.get("role") != "system":
                messages.append(msg)

        messages.append({"role": "user", "content": question})

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        search_parameters = None
        if needs_web_search:
            search_parameters = [{"type": "web_search"}]

        # –í—ã–∑—ã–≤–∞–µ–º Grok
        response = await xai_client.chat_completions_create_async(
            model="grok-2-latest",
            messages=messages,
            max_tokens=2000,
            temperature=0.7,
            search_parameters=search_parameters
        )

        answer = response["choices"][0]["message"]["content"]

        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –æ—Ç Grok ({len(answer)} —Å–∏–º–≤–æ–ª–æ–≤)")

        return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Grok: {e}")
        raise


# ============================================================================
# –û–ë–†–ê–ë–û–¢–ß–ò–ö CLAUDE (—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã)
# ============================================================================

async def handle_with_claude_technical(
    question: str,
    user_id: int,
    conversation_history: list,
    system_prompt: str
) -> str:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ Claude Sonnet 4.5

    Args:
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        conversation_history: –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç

    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç Claude
    """
    logger.info("üîµ –ò—Å–ø–æ–ª—å–∑—É–µ–º Claude Sonnet 4.5 –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞")

    try:
        from anthropic import Anthropic

        claude_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = []
        for msg in conversation_history:
            if msg.get("role") != "system":
                messages.append(msg)

        messages.append({"role": "user", "content": question})

        # –í—ã–∑—ã–≤–∞–µ–º Claude –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        loop = asyncio.get_event_loop()

        def _call_claude():
            response = claude_client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=2500,
                temperature=0.7,
                system=system_prompt,
                messages=messages
            )
            return response.content[0].text

        answer = await loop.run_in_executor(None, _call_claude)

        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –æ—Ç Claude ({len(answer)} —Å–∏–º–≤–æ–ª–æ–≤)")

        return answer

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Claude: {e}")
        raise


# ============================================================================
# –û–ë–†–ê–ë–û–¢–ß–ò–ö GEMINI VISION (–∞–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ –¥–µ—Ñ–µ–∫—Ç–æ–≤)
# ============================================================================

async def handle_with_gemini_vision(
    question: str,
    photo_file_id: str,
    bot,
    system_prompt: str
) -> str:
    """
    –ê–Ω–∞–ª–∏–∑ —Ñ–æ—Ç–æ –¥–µ—Ñ–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ Gemini Vision

    Args:
        question: –í–æ–ø—Ä–æ—Å/–æ–ø–∏—Å–∞–Ω–∏–µ –∫ —Ñ–æ—Ç–æ
        photo_file_id: ID —Ñ–æ—Ç–æ –≤ Telegram
        bot: Telegram bot instance
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç

    Returns:
        –≠–∫—Å–ø–µ—Ä—Ç–Ω–æ–µ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –ø–æ –¥–µ—Ñ–µ–∫—Ç–∞–º
    """
    logger.info("üü£ –ò—Å–ø–æ–ª—å–∑—É–µ–º Gemini Vision –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–µ—Ñ–µ–∫—Ç–∞ –Ω–∞ —Ñ–æ—Ç–æ")

    try:
        import google.generativeai as genai
        import base64
        from PIL import Image
        from io import BytesIO

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º Gemini
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
        model = genai.GenerativeModel('gemini-2.0-flash-exp')

        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–æ—Ç–æ
        file = await bot.get_file(photo_file_id)
        photo_bytes = await file.download_as_bytearray()

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
        image = Image.open(BytesIO(photo_bytes))
        buffered = BytesIO()
        image.save(buffered, format="JPEG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode()

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
        full_prompt = f"{system_prompt}\n\n–í–û–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {question}"

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        loop = asyncio.get_event_loop()

        def _call_gemini():
            response = model.generate_content([
                full_prompt,
                {"mime_type": "image/jpeg", "data": img_base64}
            ])
            return response.text

        analysis = await loop.run_in_executor(None, _call_gemini)

        logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤ –æ—Ç Gemini ({len(analysis)} —Å–∏–º–≤–æ–ª–æ–≤)")

        return analysis

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Gemini: {e}")
        raise


# ============================================================================
# –û–ë–†–ê–ë–û–¢–ß–ò–ö GEMINI IMAGE (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä—Ç–µ–∂–µ–π)
# ============================================================================

async def handle_with_gemini_image(
    question: str,
    image_prompt_system: str
) -> Dict:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —á–µ—Ä—Ç–µ–∂–∞ —á–µ—Ä–µ–∑ Gemini 2.5 Flash Image

    Args:
        question: –û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –Ω—É–∂–Ω–æ –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å
        image_prompt_system: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

    Returns:
        Dict —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏ –æ–ø–∏—Å–∞–Ω–∏–µ–º
    """
    logger.info("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Gemini 2.5 Flash Image")

    try:
        import google.generativeai as genai
        import base64
        from io import BytesIO
        from PIL import Image as PILImage

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º Gemini
        genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        model = genai.GenerativeModel('gemini-2.0-flash-exp')

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        full_prompt = f"""Create a professional technical drawing for construction:

{question}

Requirements:
- Technical blueprint style with precise measurements
- GOST standards compliance (Russian construction standards)
- Clear dimension lines with arrows
- Material specifications and labels in Russian
- High detail, engineering quality
- Scale notation (1:20, 1:50, etc.)"""

        logger.info("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Gemini...")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        loop = asyncio.get_event_loop()

        def _call_gemini():
            # –£–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ —Ö–æ—Ç–∏–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            response = model.generate_content(
                full_prompt,
                generation_config=genai.GenerationConfig(
                    temperature=0.7,
                    top_p=0.95,
                    top_k=40,
                    max_output_tokens=8192,
                    response_modalities=["IMAGE"]  # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                )
            )
            return response

        response = await loop.run_in_executor(None, _call_gemini)

        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç Gemini –ø–æ–ª—É—á–µ–Ω")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –æ—Ç–≤–µ—Ç–∞
        image_data = None
        description = ""

        # Gemini –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ parts
        for part in response.parts:
            if hasattr(part, 'inline_data') and part.inline_data:
                # –ü–æ–ª—É—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                mime_type = part.inline_data.mime_type
                image_bytes = part.inline_data.data

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BytesIO –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram
                image_data = BytesIO(image_bytes)
                image_data.name = "drawing.png"

                logger.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ ({len(image_bytes)} –±–∞–π—Ç)")
            elif hasattr(part, 'text'):
                description = part.text

        if image_data:
            return {
                "image_data": image_data,
                "description": description,
                "prompt_used": full_prompt,
                "model": "gemini-2.5-flash-image",
                "note": "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ —á–µ—Ä–µ–∑ Gemini 2.5 Flash Image"
            }
        else:
            # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç
            return {
                "description": response.text if hasattr(response, 'text') else "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
                "image_data": None,
                "prompt_used": full_prompt,
                "note": "Gemini –≤–µ—Ä–Ω—É–ª —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–º–µ—Å—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
            }

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Gemini: {e}")
        raise


# ============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================================================

def format_claude_response_for_telegram(text: str) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ Claude –¥–ª—è Telegram
    """
    # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    return text


def format_gemini_response_for_telegram(text: str) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ Gemini –¥–ª—è Telegram
    """
    return text
