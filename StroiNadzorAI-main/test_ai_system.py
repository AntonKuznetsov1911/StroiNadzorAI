"""
Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ AI ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸
ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ XAI, OpenAI DALL-E, Anthropic Claude
"""

import os
import sys
import asyncio
import logging
from dotenv import load_dotenv

# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
load_dotenv()

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ API ĞºĞ»ÑÑ‡ĞµĞ¹
XAI_API_KEY = os.getenv("XAI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")


def check_api_keys():
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ API ĞºĞ»ÑÑ‡ĞµĞ¹"""
    print("\n" + "="*60)
    print("ğŸ”‘ ĞŸĞ ĞĞ’Ğ•Ğ ĞšĞ API ĞšĞ›Ğ®Ğ§Ğ•Ğ™")
    print("="*60)

    has_xai = bool(XAI_API_KEY)
    has_openai = bool(OPENAI_API_KEY)
    has_anthropic = bool(ANTHROPIC_API_KEY)

    print(f"âœ… XAI_API_KEY: {'Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½' if has_xai else 'âŒ ĞĞ• Ğ£Ğ¡Ğ¢ĞĞĞĞ’Ğ›Ğ•Ğ'}")
    print(f"âœ… OPENAI_API_KEY: {'Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½' if has_openai else 'âŒ ĞĞ• Ğ£Ğ¡Ğ¢ĞĞĞĞ’Ğ›Ğ•Ğ'}")
    print(f"âœ… ANTHROPIC_API_KEY: {'Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½' if has_anthropic else 'âŒ ĞĞ• Ğ£Ğ¡Ğ¢ĞĞĞĞ’Ğ›Ğ•Ğ'}")

    if not has_xai:
        print("\nâš ï¸ Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•: XAI_API_KEY Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½ - Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ AI Ğ½Ğµ Ğ±ÑƒĞ´ĞµÑ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ!")

    return has_xai, has_openai, has_anthropic


async def test_xai():
    """Ğ¢ĞµÑÑ‚ XAI (Grok)"""
    print("\n" + "="*60)
    print("ğŸ¤– Ğ¢Ğ•Ğ¡Ğ¢ XAI (GROK)")
    print("="*60)

    try:
        from ai_coordinator import get_xai_client, call_xai_with_fallback

        client = get_xai_client()
        if not client:
            print("âŒ XAI ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğ½Ğµ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
            return False

        messages = [
            {"role": "system", "content": "Ğ¢Ñ‹ - Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ñƒ. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾."},
            {"role": "user", "content": "ĞšĞ°ĞºĞ¾Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ±ĞµÑ‚Ğ¾Ğ½Ğ° Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°? ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸."}
        ]

        print("ğŸ“¤ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº XAI...")
        response = await call_xai_with_fallback(messages, needs_image=False)

        print(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½:\n{response[:200]}...")
        return True

    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ XAI: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_openai_dalle():
    """Ğ¢ĞµÑÑ‚ OpenAI DALL-E"""
    print("\n" + "="*60)
    print("ğŸ¨ Ğ¢Ğ•Ğ¡Ğ¢ OPENAI DALL-E")
    print("="*60)

    try:
        from openai_dalle import generate_image_dalle, is_dalle_available

        if not is_dalle_available():
            print("âŒ DALL-E Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½ (Ğ½ĞµÑ‚ OPENAI_API_KEY)")
            return False

        print("ğŸ“¤ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº DALL-E...")
        print("ğŸ“ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚: Technical construction diagram...")

        result = await generate_image_dalle(
            prompt="Simple technical diagram of a concrete foundation with reinforcement bars, blueprint style",
            size="1024x1024",
            quality="standard"
        )

        if result and result.get("image_data"):
            print("âœ… Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾!")
            print(f"ğŸ“Š Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {result['size']}")
            print(f"ğŸ”„ Revised prompt: {result['revised_prompt'][:100]}...")

            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸
            result["image_data"].seek(0)
            with open("test_dalle_output.png", "wb") as f:
                f.write(result["image_data"].read())
            print("ğŸ’¾ Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾: test_dalle_output.png")

            return True
        else:
            print("âŒ Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğµ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾")
            return False

    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ DALL-E: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_anthropic():
    """Ğ¢ĞµÑÑ‚ Anthropic Claude"""
    print("\n" + "="*60)
    print("ğŸ§  Ğ¢Ğ•Ğ¡Ğ¢ ANTHROPIC CLAUDE")
    print("="*60)

    try:
        from ai_coordinator import call_anthropic_with_prompt

        messages = [
            {"role": "system", "content": "Ğ¢Ñ‹ - Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ñƒ. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾."},
            {"role": "user", "content": "ĞšĞ°ĞºĞ¾Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ±ĞµÑ‚Ğ¾Ğ½Ğ° Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°? ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸."}
        ]

        print("ğŸ“¤ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğº Claude...")
        response = await call_anthropic_with_prompt(messages)

        print(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½:\n{response[:200]}...")
        return True

    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Claude: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_coordination():
    """Ğ¢ĞµÑÑ‚ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸ AI"""
    print("\n" + "="*60)
    print("ğŸ¯ Ğ¢Ğ•Ğ¡Ğ¢ ĞšĞĞĞ Ğ”Ğ˜ĞĞĞ¦Ğ˜Ğ˜ AI")
    print("="*60)

    try:
        from ai_coordinator import analyze_request_and_coordinate

        # Ğ¢ĞµÑÑ‚ 1: ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ)
        print("\nğŸ“ Ğ¢ĞµÑÑ‚ 1: ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ")
        result = await analyze_request_and_coordinate(
            user_message="ĞšĞ°ĞºĞ¾Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ±ĞµÑ‚Ğ¾Ğ½Ğ° Ğ½ÑƒĞ¶ĞµĞ½ Ğ´Ğ»Ñ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ°?",
            conversation_history=[],
            system_prompt="Ğ¢Ñ‹ - Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ñƒ."
        )

        if result["error"]:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {result['error']}")
            return False

        print(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ¾Ñ‚: {result['ai_used'].upper()}")
        print(f"ğŸ“ ĞÑ‚Ğ²ĞµÑ‚: {result['text_response'][:150]}...")
        print(f"ğŸ¨ ĞÑƒĞ¶Ğ½Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ: {result['needs_image']}")

        # Ğ¢ĞµÑÑ‚ 2: Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
        print("\nğŸ“ Ğ¢ĞµÑÑ‚ 2: Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ")
        result = await analyze_request_and_coordinate(
            user_message="ĞĞ°Ñ€Ğ¸ÑÑƒĞ¹ ÑÑ…ĞµĞ¼Ñƒ ĞºĞ¾Ğ»Ğ¾Ğ´Ñ†ĞµĞ² Ğ¾Ñ‚ Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ Ğ´Ğ¾ Ñ†ĞµĞ½Ñ‚Ñ€Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ĞºĞ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸",
            conversation_history=[],
            system_prompt="Ğ¢Ñ‹ - Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ñƒ."
        )

        if result["error"]:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {result['error']}")
            return False

        print(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ¾Ñ‚: {result['ai_used'].upper()}")
        print(f"ğŸ“ ĞÑ‚Ğ²ĞµÑ‚: {result['text_response'][:150]}...")
        print(f"ğŸ¨ ĞÑƒĞ¶Ğ½Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ: {result['needs_image']}")

        if result["needs_image"] and result["image_prompt"]:
            print(f"ğŸ“ ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ DALL-E: {result['image_prompt'][:100]}...")

        return True

    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_parallel_generation():
    """Ğ¢ĞµÑÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ"""
    print("\n" + "="*60)
    print("âš¡ Ğ¢Ğ•Ğ¡Ğ¢ ĞŸĞĞ ĞĞ›Ğ›Ğ•Ğ›Ğ¬ĞĞĞ™ Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ˜")
    print("="*60)

    if not OPENAI_API_KEY:
        print("âš ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½: Ğ½ĞµÑ‚ OPENAI_API_KEY")
        return True

    try:
        from ai_coordinator import generate_text_and_image_parallel

        print("ğŸ“¤ ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ° Ğ½Ğ° Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½ÑƒÑ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ...")
        print("ğŸ“ Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ: ĞĞ°Ñ€Ğ¸ÑÑƒĞ¹ ÑÑ…ĞµĞ¼Ñƒ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ° Ñ Ğ°Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼")

        result = await generate_text_and_image_parallel(
            user_message="ĞĞ°Ñ€Ğ¸ÑÑƒĞ¹ ÑÑ…ĞµĞ¼Ñƒ Ñ„ÑƒĞ½Ğ´Ğ°Ğ¼ĞµĞ½Ñ‚Ğ° Ñ Ğ°Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼",
            conversation_history=[],
            system_prompt="Ğ¢Ñ‹ - Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº Ğ¿Ğ¾ ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ñƒ."
        )

        if result["error"]:
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {result['error']}")
            return False

        print(f"âœ… Ğ¢ĞµĞºÑÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½ Ğ¾Ñ‚: {result['ai_used'].upper()}")
        print(f"ğŸ“ ĞÑ‚Ğ²ĞµÑ‚: {result['text_response'][:150]}...")

        if result["image_result"]:
            print("âœ… Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾")
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼
            result["image_result"]["image_data"].seek(0)
            with open("test_parallel_output.png", "wb") as f:
                f.write(result["image_result"]["image_data"].read())
            print("ğŸ’¾ Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾: test_parallel_output.png")
        else:
            print("âš ï¸ Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ½Ğµ ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾")

        return True

    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸: {e}")
        import traceback
        traceback.print_exc()
        return False


async def run_all_tests():
    """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²ÑĞµÑ… Ñ‚ĞµÑÑ‚Ğ¾Ğ²"""
    print("\n" + "="*60)
    print("ğŸ§ª Ğ—ĞĞŸĞ£Ğ¡Ğš Ğ¢Ğ•Ğ¡Ğ¢ĞĞ’ AI Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ«")
    print("="*60)

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ»ÑÑ‡ĞµĞ¹
    has_xai, has_openai, has_anthropic = check_api_keys()

    results = {}

    # Ğ¢ĞµÑÑ‚ XAI
    if has_xai:
        results["XAI"] = await test_xai()
    else:
        print("\nâš ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ Ñ‚ĞµÑÑ‚ XAI: Ğ½ĞµÑ‚ API ĞºĞ»ÑÑ‡Ğ°")
        results["XAI"] = False

    # Ğ¢ĞµÑÑ‚ DALL-E
    if has_openai:
        results["DALL-E"] = await test_openai_dalle()
    else:
        print("\nâš ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ Ñ‚ĞµÑÑ‚ DALL-E: Ğ½ĞµÑ‚ API ĞºĞ»ÑÑ‡Ğ°")
        results["DALL-E"] = False

    # Ğ¢ĞµÑÑ‚ Claude
    if has_anthropic:
        results["Claude"] = await test_anthropic()
    else:
        print("\nâš ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ Ñ‚ĞµÑÑ‚ Claude: Ğ½ĞµÑ‚ API ĞºĞ»ÑÑ‡Ğ°")
        results["Claude"] = False

    # Ğ¢ĞµÑÑ‚ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸
    if has_xai or has_anthropic:
        results["ĞšĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ"] = await test_coordination()
    else:
        print("\nâš ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ Ñ‚ĞµÑÑ‚ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸: Ğ½ĞµÑ‚ AI ĞºĞ»ÑÑ‡ĞµĞ¹")
        results["ĞšĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ"] = False

    # Ğ¢ĞµÑÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸
    if has_xai and has_openai:
        results["ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ"] = await test_parallel_generation()
    else:
        print("\nâš ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ Ñ‚ĞµÑÑ‚ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸: Ğ½ÑƒĞ¶Ğ½Ñ‹ XAI + OpenAI")
        results["ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ"] = False

    # Ğ˜Ñ‚Ğ¾Ğ³Ğ¸
    print("\n" + "="*60)
    print("ğŸ“Š Ğ˜Ğ¢ĞĞ“Ğ˜ Ğ¢Ğ•Ğ¡Ğ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ¯")
    print("="*60)

    for test_name, passed in results.items():
        status = "âœ… ĞŸĞ ĞĞ™Ğ”Ğ•Ğ" if passed else "âŒ ĞŸĞ ĞĞ’ĞĞ›Ğ•Ğ"
        print(f"{test_name}: {status}")

    passed_count = sum(1 for v in results.values() if v)
    total_count = len(results)

    print(f"\nğŸ“ˆ Ğ’ÑĞµĞ³Ğ¾: {passed_count}/{total_count} Ñ‚ĞµÑÑ‚Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ğ¹Ğ´ĞµĞ½Ğ¾")

    if passed_count == total_count:
        print("\nğŸ‰ Ğ’Ğ¡Ğ• Ğ¢Ğ•Ğ¡Ğ¢Ğ« ĞŸĞ ĞĞ™Ğ”Ğ•ĞĞ«!")
    elif passed_count > 0:
        print("\nâš ï¸ ĞĞ•ĞšĞĞ¢ĞĞ Ğ«Ğ• Ğ¢Ğ•Ğ¡Ğ¢Ğ« ĞŸĞ ĞĞ’ĞĞ›Ğ•ĞĞ«")
    else:
        print("\nâŒ Ğ’Ğ¡Ğ• Ğ¢Ğ•Ğ¡Ğ¢Ğ« ĞŸĞ ĞĞ’ĞĞ›Ğ•ĞĞ«")


if __name__ == "__main__":
    asyncio.run(run_all_tests())
